{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63832ea0-0e1d-49ce-b4cc-5666b305ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, precision_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_PATH = \"C:/Users/ASUS/Desktop/fall/Dataset1(Annotated)\"  # Your prestructured dataset\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(DATASET_PATH, \"val\") if os.path.exists(os.path.join(DATASET_PATH, \"val\")) else None\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224  # Image size for CNN\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "YOLO_MODEL = \"yolov8n.pt\"  # Pretrained YOLOv8 nano model\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def plot_yolo_metrics(results):\n",
    "    \"\"\"Plot YOLO training metrics from results object\"\"\"\n",
    "    if not hasattr(results, 'results_dict'):\n",
    "        print(\"Warning: No metrics found in YOLO results\")\n",
    "        return\n",
    "    \n",
    "    metrics = results.results_dict\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training and validation metrics\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(metrics['metrics/precision(B)'], label='Train Precision')\n",
    "    plt.plot(metrics['metrics/recall(B)'], label='Train Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('YOLO Training Precision & Recall')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(metrics['metrics/mAP50(B)'], label='Train mAP@0.5')\n",
    "    plt.plot(metrics['metrics/mAP50-95(B)'], label='Train mAP@0.5:0.95')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('YOLO Training mAP Metrics')\n",
    "    plt.legend()\n",
    "    \n",
    "    if 'val/metrics/precision(B)' in metrics:\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(metrics['val/metrics/precision(B)'], label='Val Precision')\n",
    "        plt.plot(metrics['val/metrics/recall(B)'], label='Val Recall')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('YOLO Validation Precision & Recall')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(metrics['val/metrics/mAP50(B)'], label='Val mAP@0.5')\n",
    "        plt.plot(metrics['val/metrics/mAP50-95(B)'], label='Val mAP@0.5:0.95')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('YOLO Validation mAP Metrics')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"yolo_training_metrics.png\")\n",
    "    plt.show()\n",
    "\n",
    "def train_yolo_model():\n",
    "    \"\"\"Train YOLOv8 model for person detection using existing YOLO dataset\"\"\"\n",
    "    # Load pretrained YOLO model\n",
    "    model = YOLO(YOLO_MODEL)\n",
    "    \n",
    "    # Create a temporary dataset.yaml for YOLO training\n",
    "    yaml_content = f\"\"\"\n",
    "    train: {os.path.join(DATASET_PATH, 'train')}\n",
    "    val: {os.path.join(DATASET_PATH, 'val') if VAL_PATH else os.path.join(DATASET_PATH, 'train')}\n",
    "    nc: 3\n",
    "    names: ['fall', 'not_fall', 'sitting']\n",
    "    \"\"\"\n",
    "    \n",
    "    yaml_path = \"temp_dataset.yaml\"\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=50,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        name=\"yolov8_person_detection\",\n",
    "        patience=10,\n",
    "        save=True,\n",
    "        save_period=5\n",
    "    )\n",
    "    \n",
    "    # Plot YOLO training metrics\n",
    "    try:\n",
    "        plot_yolo_metrics(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not plot YOLO metrics: {e}\")\n",
    "    \n",
    "    # Handle different possible locations for the saved model\n",
    "    possible_paths = [\n",
    "        os.path.join(\"runs\", \"detect\", \"yolov8_person_detection\", \"weights\", \"best.pt\"),\n",
    "        os.path.join(\"yolov8_person_detection\", \"weights\", \"best.pt\"),\n",
    "        os.path.join(\"yolov8_person_detection\", \"best.pt\")\n",
    "    ]\n",
    "    \n",
    "    found_model = None\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            found_model = path\n",
    "            break\n",
    "    \n",
    "    if not found_model:\n",
    "        raise FileNotFoundError(\"Could not find the trained YOLO model after training. Checked paths: \" + \", \".join(possible_paths))\n",
    "    \n",
    "    # Clean up temporary yaml file\n",
    "    if os.path.exists(yaml_path):\n",
    "        os.remove(yaml_path)\n",
    "    \n",
    "    return found_model  # Return the path to the .pt model directly\n",
    "\n",
    "def plot_roc_curve(y_true, y_scores, class_names, filename=\"roc_curve.png\"):\n",
    "    \"\"\"Plot ROC curve for multi-class classification\"\"\"\n",
    "    # Binarize the output\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "    n_classes = y_true_bin.shape[1]\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_scores.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['blue', 'red', 'green', 'darkorange']\n",
    "    \n",
    "    # First plot the micro-average ROC curve\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (AUC = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "    \n",
    "    # Then plot each class's ROC curve\n",
    "    for i, color in zip(range(n_classes), colors[:n_classes]):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label='ROC curve of class {0} (AUC = {1:0.2f})'\n",
    "                 ''.format(class_names[i], roc_auc[i]))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc\n",
    "class ActivityDataset(Dataset):\n",
    "    \"\"\"Custom dataset for activity classification\"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "class FallDetectionCNN(nn.Module):\n",
    "    \"\"\"CNN model for fall detection classification\"\"\"\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(FallDetectionCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def prepare_cnn_data():\n",
    "    \"\"\"Prepare data for CNN training from the prestructured dataset\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_mapping = {\"fall\": 0, \"not_fall\": 1, \"sitting\": 2}\n",
    "    \n",
    "    # Check if dataset exists\n",
    "    if not os.path.exists(DATASET_PATH):\n",
    "        raise FileNotFoundError(f\"Dataset directory not found at {DATASET_PATH}\")\n",
    "    \n",
    "    # Process training data\n",
    "    for class_name in [\"fall\", \"not_fall\", \"sitting\"]:\n",
    "        class_dir = os.path.join(TRAIN_PATH, class_name, \"images\")\n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"Warning: Class directory not found at {class_dir}\")\n",
    "            continue\n",
    "            \n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(class_mapping[class_name])\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No training images found in the dataset\")\n",
    "    \n",
    "    # Process validation data if exists\n",
    "    if VAL_PATH:\n",
    "        for class_name in [\"fall\", \"not_fall\", \"sitting\"]:\n",
    "            class_dir = os.path.join(VAL_PATH, class_name, \"images\")\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: Validation class directory not found at {class_dir}\")\n",
    "                continue\n",
    "                \n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_file)\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(class_mapping[class_name])\n",
    "    \n",
    "    # Data transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    # Use all data for training if no validation set exists\n",
    "    if not VAL_PATH:\n",
    "        train_dataset = ActivityDataset(image_paths, labels, train_transform)\n",
    "        val_dataset = ActivityDataset(image_paths, labels, val_transform)  # Use same data for validation\n",
    "    else:\n",
    "        # Split into train and val based on directory structure\n",
    "        train_paths = [p for p in image_paths if TRAIN_PATH in p]\n",
    "        train_labels = [l for p, l in zip(image_paths, labels) if TRAIN_PATH in p]\n",
    "        val_paths = [p for p in image_paths if VAL_PATH in p]\n",
    "        val_labels = [l for p, l in zip(image_paths, labels) if VAL_PATH in p]\n",
    "        \n",
    "        train_dataset = ActivityDataset(train_paths, train_labels, train_transform)\n",
    "        val_dataset = ActivityDataset(val_paths, val_labels, val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, len(train_dataset), len(val_dataset)\n",
    "\n",
    "def train_cnn_model():\n",
    "    \"\"\"Train CNN model for activity classification\"\"\"\n",
    "    train_loader, val_loader, train_size, val_size = prepare_cnn_data()\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = FallDetectionCNN(num_classes=3).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
    "    \n",
    "    # Training loop\n",
    "    best_accuracy = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # For ROC curve\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), \"best_cnn_fall_detection.pth\")\n",
    "            print(\"Saved new best model\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"cnn_training_curves.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate on validation set for ROC curve\n",
    "    model.load_state_dict(torch.load(\"best_cnn_fall_detection.pth\"))\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"\\nValidation Set Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"fall\", \"not_fall\", \"sitting\"]))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[\"fall\", \"not_fall\", \"sitting\"], \n",
    "                yticklabels=[\"fall\", \"not_fall\", \"sitting\"])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(\"cnn_confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plot_roc_curve(all_labels, all_probs, class_names=[\"fall\", \"not_fall\", \"sitting\"], \n",
    "                  filename=\"cnn_roc_curve.png\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Step 3: Test the complete system on sample images\n",
    "class FallDetectionSystem:\n",
    "    \"\"\"Combined system using YOLOv8 for person detection and CNN for fall classification\"\"\"\n",
    "    def __init__(self, yolo_model_path, cnn_model_path):\n",
    "        # Load YOLO model - handle both .pt and .torchscript formats\n",
    "        try:\n",
    "            # First try loading as a regular YOLO model\n",
    "            self.yolo_model = YOLO(yolo_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load YOLO model directly, trying alternative loading: {e}\")\n",
    "            # If direct loading fails, try loading the TorchScript model\n",
    "            try:\n",
    "                self.yolo_model = torch.jit.load(yolo_model_path)\n",
    "                # Wrap the TorchScript model in a YOLO-compatible way\n",
    "                class WrappedModel:\n",
    "                    def __init__(self, model):\n",
    "                        self.model = model\n",
    "                        self.names = ['fall', 'not_fall', 'sitting']  # Update with your class names\n",
    "                        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                    \n",
    "                    def __call__(self, img, **kwargs):\n",
    "                        # Convert image to tensor and preprocess\n",
    "                        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float().div(255.0).unsqueeze(0)\n",
    "                        img_tensor = img_tensor.to(self.device)\n",
    "                        \n",
    "                        # Run inference\n",
    "                        with torch.no_grad():\n",
    "                            outputs = self.model(img_tensor)\n",
    "                        \n",
    "                        # Convert outputs to YOLO-like format\n",
    "                        # This is a simplified conversion - you'll need to adjust based on your model's output format\n",
    "                        results = []\n",
    "                        for i in range(outputs.shape[0]):\n",
    "                            # Process each detection in the batch\n",
    "                            # This assumes outputs is in [batch, boxes, 6] format (xyxy, conf, cls)\n",
    "                            boxes = outputs[i, :, :4]\n",
    "                            confs = outputs[i, :, 4]\n",
    "                            cls_ids = outputs[i, :, 5]\n",
    "                            \n",
    "                            # Create a Results object-like structure\n",
    "                            result = {\n",
    "                                'boxes': boxes,\n",
    "                                'scores': confs,\n",
    "                                'labels': cls_ids\n",
    "                            }\n",
    "                            results.append(result)\n",
    "                        \n",
    "                        return results\n",
    "                \n",
    "                self.yolo_model = WrappedModel(self.yolo_model)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Failed to load YOLO model from {yolo_model_path}: {e}\")\n",
    "        \n",
    "        # Load CNN model\n",
    "        self.cnn_model = FallDetectionCNN(num_classes=3).to(DEVICE)\n",
    "        self.cnn_model.load_state_dict(torch.load(cnn_model_path))\n",
    "        self.cnn_model.eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.class_names = [\"fall\", \"not_fall\", \"sitting\"]\n",
    "        self.class_colors = {\n",
    "            \"fall\": (0, 0, 255),      # Red\n",
    "            \"not_fall\": (0, 255, 0),   # Green\n",
    "            \"sitting\": (255, 0, 0)     # Blue\n",
    "        }\n",
    "    \n",
    "    def detect_and_classify(self, image_path):\n",
    "        \"\"\"Detect persons in image and classify their activity\"\"\"\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "        \n",
    "        # Convert to RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect persons with YOLO\n",
    "        try:\n",
    "            # Handle both regular YOLO model and wrapped TorchScript model\n",
    "            if hasattr(self.yolo_model, 'predict'):\n",
    "                results = self.yolo_model.predict(image_rgb)\n",
    "                boxes = results[0].boxes\n",
    "            else:\n",
    "                results = self.yolo_model(image_rgb)\n",
    "                boxes = results[0]['boxes']\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to perform detection: {e}\")\n",
    "        \n",
    "        # Process detections\n",
    "        output_image = image.copy()\n",
    "        classifications = []\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Get bounding box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0] if hasattr(box, 'xyxy') else box[:4])\n",
    "            \n",
    "            # Only consider detections with high confidence\n",
    "            if hasattr(box, 'conf'):\n",
    "                conf = box.conf.item()\n",
    "                if conf < 0.5:  # Confidence threshold\n",
    "                    continue\n",
    "            \n",
    "            # Crop person from image\n",
    "            person_img = image_rgb[y1:y2, x1:x2]\n",
    "            if person_img.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Convert to PIL Image and apply transforms\n",
    "            person_pil = Image.fromarray(person_img)\n",
    "            person_tensor = self.transform(person_pil).unsqueeze(0).to(DEVICE)\n",
    "            \n",
    "            # Classify activity with CNN\n",
    "            with torch.no_grad():\n",
    "                outputs = self.cnn_model(person_tensor)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                class_idx = predicted.item()\n",
    "                class_name = self.class_names[class_idx]\n",
    "                classifications.append(class_name)\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            color = self.class_colors.get(class_name, (255, 255, 255))\n",
    "            cv2.rectangle(output_image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(output_image, class_name, (x1, y1-10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        return output_image, classifications\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Train YOLOv8 model for person detection\n",
    "    print(\"Training YOLOv8 model for person detection...\")\n",
    "    yolo_model_path = train_yolo_model()\n",
    "    print(f\"YOLOv8 model trained and saved at: {yolo_model_path}\")\n",
    "    \n",
    "    # Step 2: Train CNN model for activity classification\n",
    "    print(\"\\nTraining CNN model for activity classification...\")\n",
    "    cnn_model = train_cnn_model()\n",
    "    print(\"CNN model trained and saved at: best_cnn_fall_detection.pth\")\n",
    "    \n",
    "    # Step 3: Test the combined system\n",
    "    print(\"\\nTesting combined system on sample images...\")\n",
    "    fall_detector = FallDetectionSystem(yolo_model_path, \"best_cnn_fall_detection.pth\")\n",
    "    \n",
    "    # Test on sample images from the validation set\n",
    "    test_images = []\n",
    "    if VAL_PATH:\n",
    "        for class_name in [\"fall\", \"not_fall\", \"sitting\"]:\n",
    "            class_dir = os.path.join(VAL_PATH, class_name, \"images\")\n",
    "            if os.path.exists(class_dir):\n",
    "                test_images.extend([os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))][:1])  # 1 image per class\n",
    "    else:\n",
    "        for class_name in [\"fall\", \"not_fall\", \"sitting\"]:\n",
    "            class_dir = os.path.join(TRAIN_PATH, class_name, \"images\")\n",
    "            if os.path.exists(class_dir):\n",
    "                test_images.extend([os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))][:1])  # 1 image per class\n",
    "    \n",
    "    for img_path in test_images[:3]:  # Test on max 3 images\n",
    "        print(f\"\\nTesting on image: {img_path}\")\n",
    "        output_image, classifications = fall_detector.detect_and_classify(img_path)\n",
    "        \n",
    "        # Save and show result\n",
    "        output_path = f\"result_{os.path.basename(img_path)}\"\n",
    "        cv2.imwrite(output_path, output_image)\n",
    "        print(f\"Classifications: {classifications}\")\n",
    "        print(f\"Result saved to {output_path}\")\n",
    "        \n",
    "        # Display result\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Fall Detection Result')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
